{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d870bd-286e-4e1e-adfd-03d2e4a6e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class FraudFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.merchant_fraud_rate_map = {}\n",
    "        self.category_fraud_rate_map = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        df = X.copy()\n",
    "        df['fraud'] = y.values\n",
    "\n",
    "        self.merchant_fraud_rate_map = df.groupby('merchant')['fraud'].mean().to_dict()\n",
    "        self.category_fraud_rate_map = df.groupby('category')['fraud'].mean().to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "\n",
    "        df = df.drop(columns=[\"zipcodeOri\", \"zipMerchant\"], errors='ignore')\n",
    "        df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "        df['age'] = df['age'].replace('U', -1)\n",
    "        df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "        df['step'] = pd.to_numeric(df['step'], errors='coerce')\n",
    "        df['hour_of_day'] = df['step'] % 24\n",
    "        df['day'] = df['step'] // 24\n",
    "        df['is_night'] = df['hour_of_day'].apply(lambda x: 1 if x <= 6 else 0)\n",
    "        df['gender'] = df['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "        df['customer_txn_count'] = df.groupby('customer')['step'].transform('count')\n",
    "        df['customer_avg_amt'] = df.groupby('customer')['amount'].transform('mean')\n",
    "        df['customer_std_amt'] = df.groupby('customer')['amount'].transform('std').fillna(0)\n",
    "        df['relative_amt'] = df['amount'] / df['customer_avg_amt']\n",
    "        df['amt_zscore'] = (df['amount'] - df['customer_avg_amt']) / df['customer_std_amt'].replace(0, 1)\n",
    "\n",
    "        df['merchant_txn_count'] = df.groupby('merchant')['step'].transform('count')\n",
    "        df['merchant_avg_amt'] = df.groupby('merchant')['amount'].transform('mean')\n",
    "        df['merchant_fraud_rate'] = df['merchant'].map(self.merchant_fraud_rate_map).fillna(0)\n",
    "\n",
    "        df['category_txn_count'] = df.groupby('category')['step'].transform('count')\n",
    "        df['category_avg_amt'] = df.groupby('category')['amount'].transform('mean')\n",
    "        df['category_fraud_rate'] = df['category'].map(self.category_fraud_rate_map).fillna(0)\n",
    "\n",
    "        df['log_amt'] = np.log1p(df['amount'])\n",
    "        amt_threshold = df['amount'].quantile(0.95)\n",
    "        df['is_high_amt'] = (df['amount'] > amt_threshold).astype(int)\n",
    "        df['is_high_risk_age'] = df['age'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
    "\n",
    "        df['category'] = LabelEncoder().fit_transform(df['category'])\n",
    "\n",
    "        drop_cols = ['step', 'customer', 'merchant', 'amount']\n",
    "        df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "        low_corr_features = ['gender', 'day', 'age', 'hour_of_day', 'is_night', 'is_high_risk_age']\n",
    "        df.drop(columns=low_corr_features, inplace=True, errors='ignore')\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c41dcee2-8b3d-4a7f-8571-b28472e2d75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model trained and saved to fraud_model.pkl\n",
      "\n",
      "ðŸ“Š Training Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    528686\n",
      "           1       1.00      1.00      1.00      6492\n",
      "\n",
      "    accuracy                           1.00    535178\n",
      "   macro avg       1.00      1.00      1.00    535178\n",
      "weighted avg       1.00      1.00      1.00    535178\n",
      "\n",
      "Confusion Matrix:\n",
      " [[528684      2]\n",
      " [     1   6491]]\n",
      "ROC-AUC Score: 0.9999999841211086\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Clean loader\n",
    "def load_clean_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip().str.replace(\"'\", \"\")\n",
    "    df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# Load and clean training data\n",
    "df_train = load_clean_csv(\"dataset.csv\")\n",
    "\n",
    "X_train = df_train.drop(columns=['fraud'])\n",
    "y_train = df_train['fraud'].astype(int)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('features', FraudFeatureEngineer()),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(pipeline, \"fraud_model.pkl\")\n",
    "print(\"âœ… Model trained and saved to fraud_model.pkl\")\n",
    "\n",
    "# Predict on training data\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_proba_train = pipeline.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Report on training\n",
    "print(\"\\nðŸ“Š Training Report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred_train))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_train, y_proba_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec8bfa84-8e9a-4074-bb00-b38d2117c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     80000\n",
      "           1       0.97      0.65      0.78      1000\n",
      "\n",
      "    accuracy                           1.00     81000\n",
      "   macro avg       0.98      0.83      0.89     81000\n",
      "weighted avg       1.00      1.00      1.00     81000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[79979    21]\n",
      " [  346   654]]\n",
      "ROC-AUC Score: 0.9936912625\n",
      "\n",
      "ðŸ“„ Results saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Load and clean test data\n",
    "df_test = load_clean_csv(\"test_hsbc_df.csv\")\n",
    "\n",
    "if 'fraud' in df_test.columns:\n",
    "    X_test = df_test.drop(columns=['fraud'])\n",
    "    y_test = df_test['fraud'].astype(int)\n",
    "    has_labels = True\n",
    "else:\n",
    "    X_test = df_test\n",
    "    y_test = None\n",
    "    has_labels = False\n",
    "\n",
    "# Load saved model\n",
    "pipeline = joblib.load(\"fraud_model.pkl\")\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "if has_labels:\n",
    "    print(\"\\nðŸ“Š Test Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No 'fraud' column in test.csv. Showing sample predictions:\")\n",
    "    print(pd.DataFrame({\n",
    "        \"Predicted Fraud\": y_pred,\n",
    "        \"Fraud Probability\": y_proba\n",
    "    }).head(10))\n",
    "\n",
    "# Save results\n",
    "df_test['predicted_fraud'] = y_pred\n",
    "df_test['fraud_probability'] = y_proba\n",
    "df_test.to_csv(\"test_predictions.csv\", index=False)\n",
    "print(\"\\nðŸ“„ Results saved to test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5906c30-6dbc-4a34-9c35-2008498d79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58de17e-a402-498d-abb8-fbefb36438d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Clean loader\n",
    "def load_clean_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip().str.replace(\"'\", \"\")\n",
    "    df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# Load and clean training data\n",
    "df_train = load_clean_csv(\"dataset.csv\")\n",
    "\n",
    "X_train = df_train.drop(columns=['fraud'])\n",
    "y_train = df_train['fraud'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2698e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Custom Keras model function\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Get feature count BEFORE pipeline (important!)\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Define the KerasClassifier *first*\n",
    "clf = KerasClassifier(\n",
    "    model=create_model,\n",
    "    model__input_dim=input_dim,   # âœ… now it works\n",
    "    epochs=30,\n",
    "    batch_size=1024,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f399d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FraudFeatureEngineer()),\n",
    "    ('model', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e70727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(pipeline, \"fraud_model_v3.pkl\")\n",
    "print(\"âœ… Model trained and saved to fraud_model_v3.pkl\")\n",
    "\n",
    "# Predict on training data\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_proba_train = pipeline.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Report on training\n",
    "print(\"\\nðŸ“Š Training Report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred_train))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_train, y_proba_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb994f6-b37a-4552-b1e1-6d4f95715c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bac22c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_dim=None, lr=0.001, epochs=10, batch_size=64, verbose=False):\n",
    "        self.input_dim = input_dim\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float32).to(self.device)\n",
    "        y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "\n",
    "        if self.input_dim is None:\n",
    "            self.input_dim = X.shape[1]\n",
    "\n",
    "        self.model = SimpleNN(self.input_dim).to(self.device)\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            for batch_X, batch_y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"Epoch {epoch+1}/{self.epochs} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X.values, dtype=torch.float32).to(self.device)\n",
    "            probs = self.model(X_tensor).cpu().numpy()\n",
    "        return np.hstack([1 - probs, probs])  # shape: [N, 2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)[:, 1]\n",
    "        return (proba >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18bfbe9b-f6c4-4569-ab8c-947217cd12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FraudFeatureEngineer()),\n",
    "    ('model', TorchClassifier(epochs=20, verbose=True))\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

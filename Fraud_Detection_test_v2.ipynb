{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b36e7b0-7533-403a-b255-46b0b7ff445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class FraudFeatureEngineerDL(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.merchant_fraud_rate_map = {}\n",
    "        self.category_fraud_rate_map = {}\n",
    "        self.category_encoder = LabelEncoder()\n",
    "        self.categorical_cols = ['category']\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        df = X.copy()\n",
    "        df['fraud'] = y.values\n",
    "        self.merchant_fraud_rate_map = df.groupby('merchant')['fraud'].mean().to_dict()\n",
    "        self.category_fraud_rate_map = df.groupby('category')['fraud'].mean().to_dict()\n",
    "        self.category_encoder.fit(df['category'])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df = df.drop(columns=[\"zipcodeOri\", \"zipMerchant\"], errors='ignore')\n",
    "        df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "        df['age'] = df['age'].replace('U', -1)\n",
    "        df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(-1)\n",
    "        df['step'] = pd.to_numeric(df['step'], errors='coerce')\n",
    "        df['hour_of_day'] = df['step'] % 24\n",
    "        df['day'] = df['step'] // 24\n",
    "        df['is_night'] = df['hour_of_day'].apply(lambda x: 1 if x <= 6 else 0)\n",
    "        df['gender'] = df['gender'].map({'M': 0, 'F': 1}).fillna(-1)\n",
    "\n",
    "        df['customer_txn_count'] = df.groupby('customer')['step'].transform('count')\n",
    "        df['customer_avg_amt'] = df.groupby('customer')['amount'].transform('mean')\n",
    "        df['customer_std_amt'] = df.groupby('customer')['amount'].transform('std').fillna(0)\n",
    "        df['relative_amt'] = df['amount'] / df['customer_avg_amt']\n",
    "        df['amt_zscore'] = (df['amount'] - df['customer_avg_amt']) / df['customer_std_amt'].replace(0, 1)\n",
    "\n",
    "        df['merchant_txn_count'] = df.groupby('merchant')['step'].transform('count')\n",
    "        df['merchant_avg_amt'] = df.groupby('merchant')['amount'].transform('mean')\n",
    "        df['merchant_fraud_rate'] = df['merchant'].map(self.merchant_fraud_rate_map).fillna(0)\n",
    "\n",
    "        df['category_txn_count'] = df.groupby('category')['step'].transform('count')\n",
    "        df['category_avg_amt'] = df.groupby('category')['amount'].transform('mean')\n",
    "        df['category_fraud_rate'] = df['category'].map(self.category_fraud_rate_map).fillna(0)\n",
    "\n",
    "        df['log_amt'] = np.log1p(df['amount'])\n",
    "        amt_threshold = df['amount'].quantile(0.95)\n",
    "        df['is_high_amt'] = (df['amount'] > amt_threshold).astype(int)\n",
    "        df['is_high_risk_age'] = df['age'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
    "\n",
    "        df['category'] = self.category_encoder.transform(df['category'])\n",
    "\n",
    "        drop_cols = ['step', 'customer', 'merchant', 'amount']\n",
    "        df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282a3aa8-b9a9-4027-800d-577e7229ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLPWithEmbeddings(nn.Module):\n",
    "    def __init__(self, num_numerical, category_cardinality, emb_dim=8, hidden_sizes=[64, 32]):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(category_cardinality, emb_dim)\n",
    "        self.fc_input_size = num_numerical + emb_dim\n",
    "\n",
    "        layers = []\n",
    "        in_dim = self.fc_input_size\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            in_dim = h\n",
    "        layers.append(nn.Linear(in_dim, 1))\n",
    "\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        emb = self.embedding(x_cat).squeeze(1)\n",
    "        x = torch.cat([x_num, emb], dim=1)\n",
    "        return torch.sigmoid(self.mlp(x)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54945c6-2044-4a5f-8f01-fe5aeddf9b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_8176\\2576508351.py:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_8176\\114908596.py:24: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Val Loss: 0.0108\n",
      "Epoch 2 - Val Loss: 0.0097\n",
      "Epoch 3 - Val Loss: 0.0094\n",
      "Epoch 4 - Val Loss: 0.0098\n",
      "Epoch 5 - Val Loss: 0.0089\n",
      "Epoch 6 - Val Loss: 0.0093\n",
      "Epoch 7 - Val Loss: 0.0090\n",
      "Epoch 8 - Val Loss: 0.0091\n",
      "Epoch 9 - Val Loss: 0.0086\n",
      "Epoch 10 - Val Loss: 0.0085\n",
      "✅ Model saved to mlp_fraud_model.pth\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Load and clean\n",
    "def load_clean_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip().str.replace(\"'\", \"\")\n",
    "    df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# Prepare\n",
    "df = load_clean_csv(\"dataset.csv\")\n",
    "X_raw = df.drop(columns=['fraud'])\n",
    "y = df['fraud'].astype(int)\n",
    "\n",
    "# Feature engineering\n",
    "fe = FraudFeatureEngineerDL()\n",
    "X_processed = fe.fit_transform(X_raw, y)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split into numerical & categorical\n",
    "cat_col = 'category'\n",
    "X_train_cat = torch.tensor(X_train[cat_col].values).long().unsqueeze(1)\n",
    "X_val_cat = torch.tensor(X_val[cat_col].values).long().unsqueeze(1)\n",
    "\n",
    "num_cols = X_train.drop(columns=[cat_col]).columns\n",
    "scaler = StandardScaler()\n",
    "X_train_num = torch.tensor(scaler.fit_transform(X_train[num_cols])).float()\n",
    "X_val_num = torch.tensor(scaler.transform(X_val[num_cols])).float()\n",
    "\n",
    "y_train_t = torch.tensor(y_train.values).float()\n",
    "y_val_t = torch.tensor(y_val.values).float()\n",
    "\n",
    "# Dataset & loader\n",
    "train_ds = TensorDataset(X_train_num, X_train_cat, y_train_t)\n",
    "val_ds = TensorDataset(X_val_num, X_val_cat, y_val_t)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=256)\n",
    "\n",
    "# Model\n",
    "model = MLPWithEmbeddings(num_numerical=X_train_num.shape[1], category_cardinality=X_train_cat.max().item()+1)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for xb_num, xb_cat, yb in train_dl:\n",
    "        preds = model(xb_num, xb_cat)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(X_val_num, X_val_cat)\n",
    "        val_loss = loss_fn(val_preds, y_val_t)\n",
    "        print(f\"Epoch {epoch+1} - Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler': scaler,\n",
    "    'feature_engineer': fe\n",
    "}, \"mlp_fraud_model.pth\")\n",
    "print(\"✅ Model saved to mlp_fraud_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db6d350-58aa-4126-8f5d-9987da18e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    422963\n",
      "         1.0       0.92      0.84      0.88      5179\n",
      "\n",
      "    accuracy                           1.00    428142\n",
      "   macro avg       0.96      0.92      0.94    428142\n",
      "weighted avg       1.00      1.00      1.00    428142\n",
      "\n",
      "Confusion Matrix:\n",
      " [[422605    358]\n",
      " [   854   4325]]\n",
      "ROC-AUC Score: 0.999111838182553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# --- Evaluate on Train Data ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_preds = model(X_train_num, X_train_cat).numpy()\n",
    "    train_labels = y_train_t.numpy()\n",
    "    train_pred_labels = (train_preds > 0.5).astype(int)\n",
    "\n",
    "print(\"\\n📊 Training Metrics:\")\n",
    "print(classification_report(train_labels, train_pred_labels))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(train_labels, train_pred_labels))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(train_labels, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e02304-fa68-4e6c-b26c-f08da40d7b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_8176\\4282833619.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_8176\\114908596.py:24: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Test Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     80000\n",
      "         1.0       0.93      0.66      0.77      1000\n",
      "\n",
      "    accuracy                           1.00     81000\n",
      "   macro avg       0.96      0.83      0.89     81000\n",
      "weighted avg       1.00      1.00      0.99     81000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[79953    47]\n",
      " [  339   661]]\n",
      "ROC-AUC Score: 0.9956460999999999\n",
      "\n",
      "📄 Predictions saved to test_mlp_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# Load test data\n",
    "def load_clean_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip().str.replace(\"'\", \"\")\n",
    "    df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "df_test = load_clean_csv(\"test_hsbc_df.csv\")\n",
    "\n",
    "# Determine if labels are present\n",
    "has_labels = 'fraud' in df_test.columns\n",
    "if has_labels:\n",
    "    y_test = torch.tensor(df_test['fraud'].astype(int).values).float()\n",
    "    X_test_raw = df_test.drop(columns=['fraud'])\n",
    "else:\n",
    "    X_test_raw = df_test\n",
    "\n",
    "# Load model and preprocessor\n",
    "checkpoint = torch.load(\"mlp_fraud_model.pth\", weights_only=False)\n",
    "fe = checkpoint['feature_engineer']\n",
    "scaler = checkpoint['scaler']\n",
    "\n",
    "X_test_processed = fe.transform(X_test_raw)\n",
    "\n",
    "# Separate categorical and numerical\n",
    "cat_col = 'category'\n",
    "X_cat = torch.tensor(X_test_processed[cat_col].values).long().unsqueeze(1)\n",
    "num_cols = X_test_processed.drop(columns=[cat_col]).columns\n",
    "X_num = torch.tensor(scaler.transform(X_test_processed[num_cols])).float()\n",
    "\n",
    "# Load model\n",
    "model = MLPWithEmbeddings(num_numerical=X_num.shape[1], category_cardinality=X_cat.max().item()+1)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    y_proba = model(X_num, X_cat).numpy()\n",
    "    y_pred = (y_proba > 0.5).astype(int)\n",
    "\n",
    "# If labels are available\n",
    "if has_labels:\n",
    "    print(\"\\n📊 Test Metrics:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
    "else:\n",
    "    print(\"\\n⚠️ No labels found — showing top predictions:\")\n",
    "    print(pd.DataFrame({\n",
    "        \"predicted_fraud\": y_pred,\n",
    "        \"fraud_probability\": y_proba\n",
    "    }).head(10))\n",
    "\n",
    "# Save output\n",
    "df_test['predicted_fraud'] = y_pred\n",
    "df_test['fraud_probability'] = y_proba\n",
    "df_test.to_csv(\"test_mlp_predictions.csv\", index=False)\n",
    "print(\"\\n📄 Predictions saved to test_mlp_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4833bf6-2aa4-4945-bb06-eb1326570303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
